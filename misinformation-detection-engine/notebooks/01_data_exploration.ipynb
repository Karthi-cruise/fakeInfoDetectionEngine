{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 – Data Exploration\n",
        "\n",
        "This notebook explores the fake news dataset used in the **Misinformation Detection Engine**.\n",
        "\n",
        "**Goals:**\n",
        "- Understand dataset structure (columns, size, missing values)\n",
        "- Inspect label distribution (`real` vs `fake`)\n",
        "- Analyze basic text statistics (lengths, word counts)\n",
        "- Note limitations and assumptions for the research report"
      ],
      "id": "dd9cf4fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# Configure plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "def find_project_root(start_dir: str) -> str:\n",
        "    \"\"\"Walk upward until we find the repo root that contains data/ and src/.\"\"\"\n",
        "    cur = os.path.abspath(start_dir)\n",
        "    while True:\n",
        "        if os.path.isdir(os.path.join(cur, \"data\")) and os.path.isdir(os.path.join(cur, \"src\")):\n",
        "            return cur\n",
        "        parent = os.path.dirname(cur)\n",
        "        if parent == cur:\n",
        "            raise FileNotFoundError(\n",
        "                \"Could not find project root containing 'data/' and 'src/'. \"\n",
        "                \"Run Jupyter from inside the 'misinformation-detection-engine' folder.\"\n",
        "            )\n",
        "        cur = parent\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_project_root(os.getcwd())\n",
        "\n",
        "PROCESSED_PATH = os.path.join(PROJECT_ROOT, \"data\", \"processed\", \"processed_fake_news.csv\")\n",
        "RAW_PATH = os.path.join(PROJECT_ROOT, \"data\", \"raw\", \"fake_news.csv\")\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"Processed path:\", PROCESSED_PATH)\n",
        "print(\"Raw path:\", RAW_PATH)\n",
        "\n",
        "\n",
        "def normalize_raw_schema(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Make raw datasets look like our expected schema: columns [label, text].\"\"\"\n",
        "    possible_text_cols = [\"text\", \"content\", \"article\"]\n",
        "    possible_title_cols = [\"title\", \"headline\"]\n",
        "    possible_label_cols = [\"label\", \"class\", \"target\"]\n",
        "\n",
        "    text_col = next((c for c in possible_text_cols if c in df_raw.columns), None)\n",
        "    title_col = next((c for c in possible_title_cols if c in df_raw.columns), None)\n",
        "    label_col = next((c for c in possible_label_cols if c in df_raw.columns), None)\n",
        "\n",
        "    if label_col is None:\n",
        "        raise ValueError(f\"Could not find label column. Expected one of: {possible_label_cols}. Got: {list(df_raw.columns)}\")\n",
        "\n",
        "    if text_col and title_col:\n",
        "        full_text = (df_raw[title_col].fillna(\"\") + \" \" + df_raw[text_col].fillna(\"\")).str.strip()\n",
        "    elif text_col:\n",
        "        full_text = df_raw[text_col].fillna(\"\")\n",
        "    elif title_col:\n",
        "        full_text = df_raw[title_col].fillna(\"\")\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Could not find text column. Expected one of: {possible_text_cols + possible_title_cols}. Got: {list(df_raw.columns)}\"\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame({\"label\": df_raw[label_col], \"text\": full_text})\n",
        "\n",
        "    # Normalize labels to {0,1} if needed\n",
        "    if df[\"label\"].dtype == \"object\":\n",
        "        df[\"label\"] = (\n",
        "            df[\"label\"]\n",
        "            .astype(str)\n",
        "            .str.lower()\n",
        "            .map({\"fake\": 1, \"false\": 1, \"real\": 0, \"true\": 0})\n",
        "        )\n",
        "\n",
        "    df = df.dropna(subset=[\"text\", \"label\"]).copy()\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Load processed if available, else fall back to raw\n",
        "if os.path.exists(PROCESSED_PATH):\n",
        "    df = pd.read_csv(PROCESSED_PATH)\n",
        "    print(\"\\nLoaded processed dataset.\")\n",
        "elif os.path.exists(RAW_PATH):\n",
        "    df_raw = pd.read_csv(RAW_PATH)\n",
        "    df = normalize_raw_schema(df_raw)\n",
        "    print(\"\\nLoaded raw dataset (normalized schema for exploration).\")\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"No dataset found. Put one of these files in place:\\n\"\n",
        "        f\"- {PROCESSED_PATH}  (run src/preprocess.py)\\n\"\n",
        "        f\"- {RAW_PATH}        (download a fake news CSV and place it here)\"\n",
        "    )\n",
        "\n",
        "print(\"\\nBasic info:\")\n",
        "display(df.head())\n",
        "print(\"\\nColumns:\", list(df.columns))\n",
        "print(\"\\nMissing values (top):\")\n",
        "display(df.isna().sum().sort_values(ascending=False).head(10))\n",
        "\n",
        "print(\"\\nDataset size:\", df.shape)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "aaa53ee8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Label distribution\n",
        "\n",
        "if \"label\" not in df.columns:\n",
        "    raise KeyError(\"Expected a 'label' column after loading/normalizing the dataset.\")\n",
        "\n",
        "# Ensure numeric {0,1}\n",
        "labels = df[\"label\"].astype(int)\n",
        "label_map = {0: \"real\", 1: \"fake\"}\n",
        "\n",
        "label_counts = labels.value_counts().sort_index()\n",
        "\n",
        "print(\"Label counts:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"{label_map.get(label, str(label))} ({label}): {count}\")\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "ax = sns.barplot(\n",
        "    x=[label_map.get(i, str(i)) for i in label_counts.index],\n",
        "    y=label_counts.values,\n",
        "    palette=\"viridis\",\n",
        ")\n",
        "ax.set_title(\"Label Distribution\")\n",
        "ax.set_xlabel(\"Class\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d2a952a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Text length analysis\n",
        "\n",
        "# Prefer cleaned text when available\n",
        "candidate_cols = [\"clean_text\", \"text\"]\n",
        "text_col = next((c for c in candidate_cols if c in df.columns), None)\n",
        "if text_col is None:\n",
        "    raise KeyError(f\"Expected one of {candidate_cols} for text content. Got: {list(df.columns)}\")\n",
        "\n",
        "texts = df[text_col].astype(str).fillna(\"\")\n",
        "\n",
        "df[\"char_len\"] = texts.str.len()\n",
        "df[\"word_len\"] = texts.str.split().apply(len)\n",
        "\n",
        "print(\"Using text column:\", text_col)\n",
        "\n",
        "print(\"\\nCharacter length stats:\")\n",
        "display(df[\"char_len\"].describe())\n",
        "\n",
        "print(\"\\nWord length stats:\")\n",
        "display(df[\"word_len\"].describe())\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "sns.histplot(df[\"char_len\"], bins=50, ax=axes[0], kde=False)\n",
        "axes[0].set_title(\"Character Length Distribution\")\n",
        "axes[0].set_xlabel(\"Number of characters\")\n",
        "\n",
        "sns.histplot(df[\"word_len\"], bins=50, ax=axes[1], kde=False)\n",
        "axes[1].set_title(\"Word Length Distribution\")\n",
        "axes[1].set_xlabel(\"Number of words\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: text length by class\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df[\"label\"].astype(int).map({0: \"real\", 1: \"fake\"}), y=df[\"word_len\"], palette=\"viridis\")\n",
        "plt.title(\"Word Length by Class\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Word count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "cc404b18"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes for Report / Paper\n",
        "\n",
        "Use this space to write **research-style observations** based on the above analysis.\n",
        "\n",
        "- **Dataset size**: `<fill in>` samples; label balance is `<balanced / imbalanced>`.\n",
        "- **Label interpretation**: `0 = real`, `1 = fake`.\n",
        "- **Typical article length**: median of `<X>` words; long tail up to `<Y>`.\n",
        "- **Potential limitations**:\n",
        "  - English-only news articles.\n",
        "  - Labels come from the dataset provider (may contain bias).\n",
        "  - May not generalize to tweets, memes, or other short/noisy text.\n",
        "\n",
        "You can refine these bullets once you see the real numbers and plots above."
      ],
      "id": "a53b6e18"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### (Optional) Next checks\n",
        "\n",
        "- Inspect a few random samples per class to understand writing style.\n",
        "- Look for duplicates or near-duplicates.\n",
        "- Note any obvious labeling noise or domain bias.\n",
        "\n",
        "You can delete this cell later if you don’t need it."
      ],
      "id": "3c9e9c10"
    },
    {
      "cell_type": "code",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# (Optional) Show a few samples per class\n",
        "\n",
        "label_map = {0: \"real\", 1: \"fake\"}\n",
        "\n",
        "for cls in [0, 1]:\n",
        "    sample = df[df[\"label\"].astype(int) == cls].sample(n=min(3, (df[\"label\"].astype(int) == cls).sum()), random_state=42)\n",
        "    print(f\"\\n=== Samples for {label_map[cls].upper()} ===\")\n",
        "    for i, row in sample.iterrows():\n",
        "        txt_col = \"clean_text\" if \"clean_text\" in df.columns else \"text\"\n",
        "        print(\"-\", str(row[txt_col])[:300], \"...\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0d57f1b6"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}